OBJECT Detection and Localization
drive link :https://drive.google.com/drive/folders/1rL7K0oOxLwA9JD3_BmJz7gAopriAx-6-?usp=sharing
Flipkart Grid Challenge:

Problem Statement:

-->The 2019 GRiD challenge for students is to leverage a pre-defined data-set from 
   Flipkart to enable ‘Vertical Classification’ using images.

Data Description:

-->You’re given two different files - Training.csv and Test.csv. 
   The training data set consists samples to train your model. 
   The test data set should be used for submission after predicting bounding box dimensions and same will be used for evaluations. 
   You can download the image data set for the set of all the images you'll require during the challenge. 

 Note:The image data set is a huge file of around 13 GB.(Link for dataset:"http://www.mediafire.com/file/ue7q4i4ap52okm4/images.zip/file")

-->Each csv file consists of the following variables:
   image_name,x1,x2,y1,y2 where

	image_name   =	 image name
	 x1	     =   x position of the bounding box
	 x2	     =   x+width of bounding box
	 y1 	     =   y position of the bounding box
	 y2	     =   y+height of bounding box

-->STEPS TO BE FOLLOWED FOR SOLVING THE ABOVE PROBLEM ARE:

Here we do the custom training to the model "faster_rcnn_resnet101_coco_11_06_2017"[Custom object detection using tensorflow API] .

STEP-1:

1.Download the given dataset ,train.csv file and test.csv
2.To begin, install the Tensorflow and all of required dependencies.
	-pip install tensorflow
3.Now clone the tensorflow models through command:
	-git clone https://github.com/tensorflow/models
4.Next head to prtoc releases page and download the "protoc-3.4.0-win32.zip", extract it and you will find protoc.exe in the bin directory
5.Move the "protoc.exe" file to models->research(i.e into research directory)
6.Now execute the command:
	- "protoc object_detection/protos/*.proto --python_out=."

STEP-2:

1.Collect a few hundred images that contain your object - The bare minimum would be about 100, ideally more like 500+, but, the more images you have, the more tedious step 2 is...
2.Annotate/label the images using LabelImg.
3.The above step is basically drawing boxes around your object(s) in an image.
4.This labelImg automatically will create an XML file that describes the object(s) in the pictures.
3.Split this image data into train/test samples
4.Create train.csv and test.csv file for above samples.
	-this can be done through xml_to_csv.py file which is available from link :" https://github.com/datatrain/raccoon_dataset/blob/master/xml_to_csv.py"
5.create the new folder named "data" and now place the generated ".csv" files in data folder.

STEP-3:
1.Firstly change the directory to :"models/research"
1.Finally, install the object_dection library formally by doing the following from within the models->research directory:
	-python setup.py install

2.Now run the generate_tfrecord.py script. We will run it twice, once for the train TFRecord and once for the test TFRecord.
	-python generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=data/train.record
	-python generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=data/test.record

3.Now generated files are available in data folder.
Note:Don't change the directory path

STEP-4:
1.TensorFlow has quite a few pre-trained models with checkpoint files available, along with configuration files. 
2.Here we are using "faster_rcnn_resnet101_coco_11_06_2017".
3.using the following checkpoint and configuration file
  config_file :-wget https://raw.githubusercontent.com/tensorflow/models/master/object_detection/samples/configs/faster_rcnn_resnet101_coco_11_06_2017.config
  checkpoint :-wget http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017
4.Create new directory "training"
5.Put the config in the training directory.
6.Extract the faster_rcnn_resnet101_coco_11_06_2017 in the research directory.
8.Now in this file search for all of the PATH_TO_BE_CONFIGURED points and change them :
	--->fine_tune_checkpoint: "faster_rcnn_resnet101_coco_11_06_2017/model.ckpt"
	--->train_input_reader: {
  	    tf_record_input_reader {
    `	   input_path: "data/train.record"
  		}
           label_map_path: "data/object-detection.pbtxt"
		}
	---->eval_input_reader: {
  		tf_record_input_reader {
    		input_path: "data/test.record"
  		}
  	label_map_path: "training/object-detection.pbtxt"

9.create object-detection.pbtxt file and save it in training folder :
	-the format of object-detction is as follows:    item {
			  			id: 1
  						name: 'footware'
					             }
STEP-5:
1.In this step delete the file train.py in research directory.
2.copy the train.py file that is available in "research/object_detection/legacy"
3.Now from slim directory which is in research directory , copy all the files in it and paste it in research directory
4.Now we start the training through command:
	-python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=faster_rcnn_resnet101_coco_11_06_2017
5.This takes few time(based on resources available)
6.This generates data in training directory which consist of checkpoints that can be viewed via TensorBoard.

STEP-6:
1.Now finally we test our model running through few commands.
2.Firstly delete the file "export_inference_graph.py" available in research directory.
3.Now from research/object_detection copy the "export_inference_graph.py" and paste in research directory.
4.And run the command:
	###->python3 export_inference_graph.py \
    	     --input_type image_tensor \
             --pipeline_config_path training/faster_rcnn_resnet101_coco_11_06_2017.config \
             --trained_checkpoint_prefix training/model.ckpt-10856 \         #here model.ckpt-10856 is one of checkpoint available in training directory# 
             --output_directory mydata
5.This command generates the directory "mymodel" (model name)
6.upload the test.csv file in research directory
6.clean the test_images directory data in research directory.
6.place the image need to be tested in test_images 
6.Now load the object-detction.ipynb file from research/object_detection
7.Make the following changes in .ipynb file:
	MODEL_NAME = 'mymodel'
	PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'
	PATH_TO_LABELS = os.path.join('training', 'object-detection.pbtxt')
	NUM_CLASSES = 1     #####['no of classes' in data']#####
	**delete next followinig cell
	(as required)TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}.jpg'.format(i)) for i in range(3, 8) ]
8.Now run all cells.
9.For bounding box data , iterate over box variable at last cell
10.At last cell we see visualized data i.e. testing image with bounding box
 over object.

reference:

video link: "https://pythonprogramming.net/introduction-use-tensorflow-object-detection-api-tutorial/"
